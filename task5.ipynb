{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtmpbF25gRUO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from sklearn.utils import shuffle\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "\n",
        "import os\n",
        "print(os.getcwd())\n",
        "\n",
        "/content\n",
        "\n",
        "import zipfile\n",
        "if \"/kaggle/working/food-101.zip\" in os.listdir():\n",
        "    print(\"Dataset already exists\")\n",
        "else:\n",
        "    print(\"Downloading the data...\")\n",
        "    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "    print(\"Dataset downloaded!\")\n",
        "    print(\"Extracting data..\")\n",
        "    !tar xzvf food-101.tar.gz > /dev/null 2>&1\n",
        "    print(\"Extraction done!\")\n",
        "\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the path to the source directory\n",
        "source_dir = '/content/food-101'\n",
        "\n",
        "# Define the destination directory\n",
        "destination_dir = '/kaggle/working/'\n",
        "\n",
        "# Copy the directory\n",
        "shutil.copytree(source_dir, destination_dir, dirs_exist_ok=True)\n",
        "\n",
        "print(f\"Copied {source_dir} to {destination_dir}\")\n",
        "\n",
        "# Optionally, list the contents of the destination directory to verify\n",
        "print(\"Contents of the destination directory:\")\n",
        "print(os.listdir(destination_dir))\n",
        "\n",
        "\n",
        "['meta', 'README.txt', 'license_agreement.txt', 'images']\n",
        "\n",
        "classes = open(\"/kaggle/working/meta/classes.txt\", 'r').read().splitlines()\n",
        "classes_21 = classes[:20] + ['other']\n",
        "classes_21, len(classes_21)\n",
        "\n",
        "(['apple_pie',\n",
        "  'baby_back_ribs',\n",
        "  'baklava',\n",
        "  'beef_carpaccio',\n",
        "  'beef_tartare',\n",
        "  'beet_salad',\n",
        "  'beignets',\n",
        "  'bibimbap',\n",
        "  'bread_pudding',\n",
        "  'breakfast_burrito',\n",
        "  'bruschetta',\n",
        "  'caesar_salad',\n",
        "  'cannoli',\n",
        "  'caprese_salad',\n",
        "  'carrot_cake',\n",
        "  'ceviche',\n",
        "  'cheesecake',\n",
        "  'cheese_plate',\n",
        "  'chicken_curry',\n",
        "  'chicken_quesadilla',\n",
        "  'other'],\n",
        " 21)\n",
        "\n",
        "!echo \"Testing images\"\n",
        "!head -n 5 /kaggle/working/meta//test.txt\n",
        "!echo -e \"\\nTraining images\"\n",
        "!head -n 5 /kaggle/working/meta/train.txt | head -n 5\n",
        "\n",
        "Testing images\n",
        "apple_pie/1011328\n",
        "apple_pie/101251\n",
        "apple_pie/1034399\n",
        "apple_pie/103801\n",
        "apple_pie/1038694\n",
        "\n",
        "Training images\n",
        "apple_pie/1005649\n",
        "apple_pie/1014775\n",
        "apple_pie/1026328\n",
        "apple_pie/1028787\n",
        "apple_pie/1043283\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def prep_df(path: str) -> pd.DataFrame:\n",
        "    # Read lines from the file\n",
        "    array = open(path, 'r').read().splitlines()\n",
        "\n",
        "    # Base path where images are located\n",
        "    base_path = \"/kaggle/working/images/\"\n",
        "\n",
        "    # Initialize lists to store labels and full paths\n",
        "    labels = []\n",
        "    full_paths = []\n",
        "\n",
        "    # Iterate over each line in the array\n",
        "    for line in array:\n",
        "        # Split the line into label and image filename\n",
        "        parts = line.split('/')\n",
        "        label = parts[0]  # Assuming label is the first part before '/'\n",
        "        img_filename = parts[1]  # Assuming image filename is the second part after '/'\n",
        "\n",
        "        # Construct full path to the image\n",
        "        img_path = base_path + label + \"/\" + img_filename + \".jpg\"\n",
        "\n",
        "        # Append label and full path to respective lists\n",
        "        labels.append(label)\n",
        "        full_paths.append(img_path)\n",
        "\n",
        "    # Create a DataFrame from lists of labels and full paths\n",
        "    imgs_df = pd.DataFrame({\n",
        "        'label': labels,\n",
        "        'path': full_paths\n",
        "    })\n",
        "\n",
        "    # Shuffle the DataFrame to randomize the order\n",
        "    imgs_df = shuffle(imgs_df)\n",
        "\n",
        "    return imgs_df\n",
        "\n",
        "\n",
        "train_imgs = prep_df('/kaggle/working/meta/train.txt')\n",
        "test_imgs = prep_df('/kaggle/working/meta/test.txt')\n",
        "\n",
        "train_imgs.head(5)\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "\n",
        "num_rows = 3\n",
        "num_cols = 8\n",
        "\n",
        "\n",
        "for idx in range(num_rows * num_cols):\n",
        "    random_idx = np.random.randint(0, train_imgs.shape[0])\n",
        "    img = plt.imread(train_imgs.path.iloc[random_idx])\n",
        "\n",
        "    label = train_imgs.label.iloc[random_idx]\n",
        "\n",
        "    ax = plt.subplot(num_rows, num_cols, idx + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "\n",
        "\n",
        "# Data augmentation for training\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       torchvision.transforms.AutoAugment(torchvision.transforms.AutoAugmentPolicy.IMAGENET),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "# Data augmentation for testing\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class Label_encoder:\n",
        "    def __init__(self, labels):\n",
        "        labels = list(set(labels))\n",
        "        self.labels = {label: idx for idx, label in enumerate(classes)}\n",
        "\n",
        "    def get_label(self, idx):\n",
        "        return list(self.labels.keys())[idx]\n",
        "\n",
        "    def get_idx(self, label):\n",
        "        return self.labels[label]\n",
        "\n",
        "encoder = Label_encoder(classes)\n",
        "for i in range(20):\n",
        "    print(encoder.get_label(i), encoder.get_idx( encoder.get_label(i) ))\n",
        "\n",
        "\n",
        "class Food20(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataframe.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.dataframe.path.iloc[idx]\n",
        "        image = Image.open(img_name)\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "        label = encoder.get_idx(self.dataframe.label.iloc[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "train_dataset = Food20(train_imgs, transform=train_transforms)\n",
        "test_dataset = Food20(test_imgs, transform=test_transforms)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "\n",
        "# Testing the retrieval of a single image\n",
        "for i in range(10):\n",
        "    image = train_dataset.__getitem__(i)\n",
        "    print(encoder.get_label(image[1]), image[0].shape)\n",
        "\n",
        "onion_rings torch.Size([3, 224, 224])\n",
        "grilled_salmon torch.Size([3, 224, 224])\n",
        "donuts torch.Size([3, 224, 224])\n",
        "mussels torch.Size([3, 224, 224])\n",
        "beef_tartare torch.Size([3, 224, 224])\n",
        "hot_dog torch.Size([3, 224, 224])\n",
        "hummus torch.Size([3, 224, 224])\n",
        "filet_mignon torch.Size([3, 224, 224])\n",
        "eggs_benedict torch.Size([3, 224, 224])\n",
        "ceviche torch.Size([3, 224, 224])\n",
        "\n",
        "weights = models.DenseNet201_Weights.IMAGENET1K_V1\n",
        "model = models.densenet201(weights = weights)\n",
        "\n",
        "\n",
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "import requests as reqs\n",
        "\n",
        "url = \"https://github.com/Prakhar998/Food-Classification/raw/master/food_classifier.pt\"\n",
        "r = reqs.get(url, allow_redirects=True)\n",
        "\n",
        "open(\"./food_classifier.pt\", \"wb\").write(r.content)\n",
        "\n",
        "81841763\n",
        "\n",
        "checkpoint_path = \"./food_classifier.pt\"\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(1920,1024),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(1024,101),\n",
        ")\n",
        "\n",
        "model.classifier = classifier\n",
        "model.load_state_dict(torch.load(checkpoint_path,map_location='cpu'),strict=False)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "DenseNet(\n",
        "  (features): Sequential(\n",
        "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    (relu0): ReLU(inplace=True)\n",
        "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
        "    (denseblock1): _DenseBlock(\n",
        "      (denselayer1): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer2): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer3): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer4): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer5): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer6): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "    )\n",
        "    (transition1): _Transition(\n",
        "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    )\n",
        "    (denseblock2): _DenseBlock(\n",
        "      (denselayer1): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer2): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer3): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer4): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer5): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer6): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer7): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer8): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer9): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer10): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer11): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer12): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "    )\n",
        "    (transition2): _Transition(\n",
        "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    )\n",
        "    (denseblock3): _DenseBlock(\n",
        "      (denselayer1): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer2): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer3): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer4): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer5): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer6): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer7): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer8): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer9): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer10): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer11): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer12): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer13): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer14): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer15): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer16): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer17): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer18): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer19): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer20): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer21): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer22): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer23): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer24): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer25): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer26): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer27): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer28): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer29): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer30): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer31): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer32): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer33): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer34): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer35): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer36): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer37): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer38): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer39): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer40): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer41): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer42): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer43): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer44): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer45): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer46): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer47): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer48): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "    )\n",
        "    (transition3): _Transition(\n",
        "      (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    )\n",
        "    (denseblock4): _DenseBlock(\n",
        "      (denselayer1): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer2): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer3): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer4): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer5): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer6): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer7): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer8): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer9): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer10): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer11): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer12): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer13): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer14): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer15): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer16): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer17): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer18): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer19): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer20): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer21): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer22): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer23): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer24): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer25): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer26): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer27): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer28): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer29): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer30): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer31): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "      (denselayer32): _DenseLayer(\n",
        "        (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu1): ReLU(inplace=True)\n",
        "        (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu2): ReLU(inplace=True)\n",
        "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      )\n",
        "    )\n",
        "    (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  )\n",
        "  (classifier): Sequential(\n",
        "    (0): Linear(in_features=1920, out_features=1024, bias=True)\n",
        "    (1): LeakyReLU(negative_slope=0.01)\n",
        "    (2): Linear(in_features=1024, out_features=101, bias=True)\n",
        "  )\n",
        ")\n",
        "\n",
        "#hyper parameters\n",
        "num_epochs = 3\n",
        "\n",
        "# loss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# all parameters are being optimized\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=[0.9, 0.999])\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device):\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Setup train loss and train accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  print(\"--> Training Progress\")\n",
        "  # Loop through data loader data batches\n",
        "  for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
        "      # Send data to target device\n",
        "      images, labels = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      y_pred = model(images)\n",
        "\n",
        "      # 2. Calculate  and accumulate loss\n",
        "      loss = loss_fn(y_pred, labels)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # 3. Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 4. Loss backward\n",
        "      loss.backward()\n",
        "\n",
        "      # 5. Optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "      # Calculate and accumulate accuracy metric across all batches\n",
        "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "      train_acc += (y_pred_class == labels).sum().item()/len(y_pred)\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device):\n",
        "  # Put model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # Setup test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # Turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "      print(\"--> Testing Progress\")\n",
        "      # Loop through DataLoader batches\n",
        "      for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
        "          # Send data to target device\n",
        "          images, labels = X.to(device), y.to(device)\n",
        "\n",
        "          # 1. Forward pass\n",
        "          test_pred_logits = model(images)\n",
        "\n",
        "          # 2. Calculate and accumulate loss\n",
        "          loss = loss_fn(test_pred_logits, labels)\n",
        "          test_loss += loss.item()\n",
        "\n",
        "          # Calculate and accumulate accuracy\n",
        "          test_pred_labels = torch.argmax(torch.softmax(test_pred_logits, dim=1), dim=1)\n",
        "\n",
        "          test_acc += ((test_pred_labels == labels).sum().item()/len(test_pred_labels))\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device):\n",
        "    # Create empty results dictionary\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": [],\n",
        "        'best train acc': (0, 0),\n",
        "        \"best_model\": dict()\n",
        "    }\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
        "\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           dataloader=train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer,\n",
        "                                           device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "                                        dataloader=test_dataloader,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"train_acc: {train_acc:.4f} | \"\n",
        "            f\"test_loss: {test_loss:.4f} | \"\n",
        "            f\"test_acc: {test_acc:.4f}\"\n",
        "            f\"\\n\\n=============================\\n\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"test_loss\"].append(test_loss)\n",
        "        history[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        if test_loss < history[\"test_acc\"][len(history[\"test_acc\"]) - 1]:\n",
        "            history[\"best_model\"] = model.state_dict()\n",
        "\n",
        "        if test_acc > 0.95:\n",
        "            break\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return model, history\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Remove\n",
        "def evaluate(model, dataloader):\n",
        "\n",
        "  random = np.random.randint(0, len(dataloader))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "\n",
        "    for images, labels in tqdm(dataloader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "\n",
        "      preds = torch.argmax(torch.softmax(outputs, 1), 1)\n",
        "\n",
        "      # Converting this problem to a problem with 21 clases only\n",
        "      preds = np.array([pred.cpu() if pred < 20 else 20 for pred in preds])\n",
        "      labels = np.array([label.cpu() if label < 20 else 20 for label in labels])\n",
        "\n",
        "      n_samples += labels.shape[0]\n",
        "      n_correct += (preds==labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(acc)\n",
        "\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "def evaluate(model, dataloader):\n",
        "    device = next(model.parameters()).device  # Get the device of the model\n",
        "    model.eval()\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for images, labels in tqdm(dataloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        preds = torch.argmax(torch.softmax(outputs, 1), 1)\n",
        "\n",
        "        # Converting predictions and labels to numpy arrays\n",
        "        preds_np = preds.cpu().numpy()\n",
        "        labels_np = labels.cpu().numpy()\n",
        "\n",
        "        # Store all predictions and labels for later metrics calculation\n",
        "        all_preds.extend(preds_np)\n",
        "        all_labels.extend(labels_np)\n",
        "\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (preds == labels).sum().item()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Generate classification report\n",
        "    class_report = classification_report(all_labels, all_preds)\n",
        "\n",
        "    print(f'Accuracy: {acc:.2f}%')\n",
        "    print(f'F1 Score: {f1:.4f}%')\n",
        "    print('Confusion Matrix:')\n",
        "    print(conf_matrix)\n",
        "    print('Classification Report:')\n",
        "    print(class_report)\n",
        "\n",
        "    return acc, f1, conf_matrix, class_report\n",
        "\n",
        "\n",
        "evaluate(model,test_loader)\n",
        "\n",
        "\n",
        "(91.46534653465346,\n",
        " 0.9146858306689128,\n",
        " array([[213,   1,   0, ...,   2,   0,   2],\n",
        "        [  0, 231,   0, ...,   0,   1,   0],\n",
        "        [  5,   0, 237, ...,   1,   0,   0],\n",
        "        ...,\n",
        "        [  2,   1,   0, ..., 236,   0,   0],\n",
        "        [  0,   0,   0, ...,   0, 198,   0],\n",
        "        [  0,   0,   0, ...,   0,   0, 244]]),\n",
        " '              precision    recall  f1-score   support\\n\\n           0       0.85      0.85      0.85       250\\n           1       0.89      0.92      0.91       250\\n           2       0.99      0.95      0.97       250\\n           3       0.90      0.97      0.94       250\\n           4       0.91      0.87      0.89       250\\n           5       0.81      0.92      0.86       250\\n           6       0.96      0.94      0.95       250\\n           7       0.94      0.98      0.96       250\\n           8       0.87      0.76      0.81       250\\n           9       0.92      0.89      0.90       250\\n          10       0.86      0.90      0.88       250\\n          11       0.86      0.95      0.90       250\\n          12       0.94      0.98      0.96       250\\n          13       0.90      0.95      0.92       250\\n          14       0.96      0.81      0.88       250\\n          15       0.89      0.84      0.86       250\\n          16       0.86      0.81      0.84       250\\n          17       0.91      0.98      0.95       250\\n          18       0.86      0.87      0.87       250\\n          19       0.94      0.92      0.93       250\\n          20       0.92      0.99      0.95       250\\n          21       0.92      0.67      0.78       250\\n          22       0.71      0.82      0.76       250\\n          23       1.00      0.93      0.96       250\\n          24       0.97      0.89      0.93       250\\n          25       0.92      0.97      0.95       250\\n          26       0.89      0.88      0.89       250\\n          27       0.94      0.95      0.95       250\\n          28       0.90      0.96      0.93       250\\n          29       0.97      0.93      0.95       250\\n          30       1.00      0.97      0.98       250\\n          31       0.98      0.94      0.96       250\\n          32       0.97      0.94      0.96       250\\n          33       1.00      0.99      1.00       250\\n          34       0.94      0.94      0.94       250\\n          35       0.95      0.98      0.96       250\\n          36       0.90      0.92      0.91       250\\n          37       0.73      0.86      0.79       250\\n          38       0.95      0.97      0.96       250\\n          39       0.79      0.84      0.81       250\\n          40       0.98      0.94      0.96       250\\n          41       0.97      0.95      0.96       250\\n          42       0.89      0.94      0.92       250\\n          43       0.96      0.92      0.94       250\\n          44       0.97      0.90      0.93       250\\n          45       0.94      0.98      0.96       250\\n          46       0.93      0.87      0.90       250\\n          47       0.93      0.89      0.91       250\\n          48       0.88      0.90      0.89       250\\n          49       0.92      0.89      0.90       250\\n          50       0.91      0.87      0.89       250\\n          51       1.00      0.89      0.94       250\\n          52       0.95      0.96      0.95       250\\n          53       0.88      0.96      0.92       250\\n          54       0.99      0.96      0.97       250\\n          55       0.95      0.93      0.94       250\\n          56       0.85      0.86      0.85       250\\n          57       0.95      0.88      0.92       250\\n          58       0.97      0.82      0.89       250\\n          59       0.85      0.90      0.88       250\\n          60       0.92      0.92      0.92       250\\n          61       1.00      0.92      0.95       250\\n          62       0.95      0.92      0.93       250\\n          63       0.99      1.00      0.99       250\\n          64       1.00      0.92      0.96       250\\n          65       0.97      0.96      0.96       250\\n          66       0.90      0.90      0.90       250\\n          67       0.89      0.88      0.89       250\\n          68       0.94      0.98      0.96       250\\n          69       0.99      0.98      0.98       250\\n          70       0.97      0.98      0.97       250\\n          71       0.88      0.93      0.90       250\\n          72       0.98      0.94      0.96       250\\n          73       0.78      0.92      0.85       250\\n          74       0.99      0.94      0.96       250\\n          75       0.91      0.98      0.94       250\\n          76       0.96      0.92      0.94       250\\n          77       0.76      0.76      0.76       250\\n          78       0.95      0.96      0.95       250\\n          79       0.95      0.90      0.92       250\\n          80       0.94      0.94      0.94       250\\n          81       0.94      0.93      0.93       250\\n          82       0.91      0.81      0.86       250\\n          83       0.93      0.94      0.93       250\\n          84       0.91      0.85      0.88       250\\n          85       0.89      0.95      0.92       250\\n          86       0.95      0.96      0.95       250\\n          87       0.92      0.87      0.89       250\\n          88       0.95      0.97      0.96       250\\n          89       0.85      0.96      0.90       250\\n          90       0.97      0.98      0.97       250\\n          91       0.94      0.97      0.95       250\\n          92       0.96      0.96      0.96       250\\n          93       0.78      0.66      0.71       250\\n          94       0.93      0.90      0.91       250\\n          95       0.95      0.92      0.94       250\\n          96       0.77      0.93      0.84       250\\n          97       0.99      0.95      0.97       250\\n          98       0.75      0.94      0.83       250\\n          99       0.85      0.79      0.82       250\\n         100       0.91      0.98      0.94       250\\n\\n    accuracy                           0.91     25250\\n   macro avg       0.92      0.91      0.91     25250\\nweighted avg       0.92      0.91      0.91     25250\\n')\n",
        "\n",
        "class Label_encoder_21:\n",
        "    def __init__(self, labels):\n",
        "        labels = list(set(labels))\n",
        "        self.labels = {label: idx for idx, label in enumerate(labels)}\n",
        "\n",
        "    def get_label(self, idx):\n",
        "        return list(self.labels.keys())[idx]\n",
        "\n",
        "    def get_idx(self, label):\n",
        "        return self.labels[label]\n",
        "\n",
        "encoder_21 = Label_encoder(classes_21)\n",
        "encoder_21.get_label(0), encoder.get_idx( encoder_21.get_label(0) )\n",
        "\n",
        "('apple_pie', 0)\n",
        "\n",
        "#This line of code saves the best model's state dictionary (or parameters) from the training history to a file named solution.pth.\n",
        "torch.save(history['best_model'], \"./solution.pth\")\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "if os.path.exists(\"./solution.pth\"):\n",
        "    print(\"solution.pth exists in the current directory.\")\n",
        "else:\n",
        "    print(\"solution.pth does not exist in the current directory.\")\n",
        "\n",
        "solution.pth exists in the current directory.\n",
        "\n",
        "torch.save(model.state_dict(), 'saved_model.pth')\n",
        "\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "def classify_image(image_path, model, label_encoder, device):\n",
        "    # Load and preprocess the input image\n",
        "    image = Image.open(image_path)\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Perform prediction\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        output = model(image_tensor)\n",
        "\n",
        "    # Get predicted class index\n",
        "    _, predicted_idx = torch.max(output, 1)\n",
        "    predicted_idx = predicted_idx.item()\n",
        "\n",
        "    # Map index to class name\n",
        "    predicted_label = label_encoder.get_label(predicted_idx)\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Load the saved model and label encoder\n",
        "model = models.densenet201(weights=None)\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(1920, 1024),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(1024, 101),\n",
        ")\n",
        "model.classifier = classifier\n",
        "model.load_state_dict(torch.load(\"solution.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "label_encoder = Label_encoder(classes)\n",
        "\n",
        "\n",
        "# Classify an image\n",
        "image_path = \"/kaggle/working/images/ice_cream/988684.jpg\"  # Replace with the path to your image\n",
        "predicted_label = classify_image(image_path, model, label_encoder, device)\n",
        "print(\"Predicted Label:\", predicted_label)\n",
        "\n",
        "Predicted Label: ice_cream\n",
        "\n",
        "# Define the model architecture\n",
        "model = models.densenet201(weights=None)\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(1920, 1024),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(1024, 101),\n",
        ")\n",
        "model.classifier = classifier\n",
        "\n",
        "# Load the trained model parameters\n",
        "model.load_state_dict(torch.load(\"solution.pth\", map_location=torch.device('cpu')))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define a dummy input for tracing\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# Convert the model to TorchScript using tracing\n",
        "traced_model = torch.jit.trace(model, dummy_input)\n",
        "\n",
        "# Save the TorchScript model\n",
        "traced_model.save(\"model_scripted.pt\")\n",
        "\n",
        "print(\"Model converted to TorchScript and saved as 'model_scripted.pt'\")\n",
        "\n",
        "Model converted to TorchScript and saved as 'model_scripted.pt'\n",
        "\n",
        "# Load the TorchScript model\n",
        "scripted_model = torch.jit.load(\"model_scripted.pt\")\n",
        "scripted_model.to(device)\n",
        "scripted_model.eval()\n",
        "\n",
        "def classify_image_with_scripted_model(image_path, model, label_encoder, device):\n",
        "    # Load and preprocess the input image\n",
        "    image = Image.open(image_path)\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Perform prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "\n",
        "    # Get predicted class index\n",
        "    _, predicted_idx = torch.max(output, 1)\n",
        "    predicted_idx = predicted_idx.item()\n",
        "\n",
        "    # Map index to class name\n",
        "    predicted_label = label_encoder.get_label(predicted_idx)\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Classify an image using the TorchScript model\n",
        "image_path = \"/kaggle/working/images/ice_cream/988684.jpg\"  # Replace with the path to your image\n",
        "predicted_label = classify_image_with_scripted_model(image_path, scripted_model, label_encoder, device)\n",
        "print(\"Predicted Label with Scripted Model:\", predicted_label)\n",
        "\n",
        "Predicted Label with Scripted Model: ice_cream\n",
        "\n",
        "import torch\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from torchvision import transforms\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Assume you have already loaded and prepared your TorchScript model and label encoder\n",
        "scripted_model = torch.jit.load(\"model_scripted.pt\")\n",
        "scripted_model.to(device)\n",
        "scripted_model.eval()\n",
        "\n",
        "# Define the function to classify an image with the TorchScript model\n",
        "def classify_image_with_scripted_model(image, model, label_encoder, device):\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Perform prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "\n",
        "    # Get predicted class index\n",
        "    _, predicted_idx = torch.max(output, 1)\n",
        "    predicted_idx = predicted_idx.item()\n",
        "\n",
        "    # Map index to class name\n",
        "    predicted_label = label_encoder.get_label(predicted_idx)\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Function to classify an image from a Google URL\n",
        "def classify_google_image(url, model, label_encoder, device):\n",
        "    try:\n",
        "        # Fetch the image from the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for bad responses\n",
        "\n",
        "        # Open the image using PIL\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "\n",
        "        # Check if the image could be opened\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        # Classify the image using the existing function\n",
        "        predicted_label = classify_image_with_scripted_model(image, model, label_encoder, device)\n",
        "\n",
        "        return predicted_label\n",
        "\n",
        "    except requests.exceptions.HTTPError as errh:\n",
        "        print(f\"HTTP Error: {errh}\")\n",
        "    except requests.exceptions.ConnectionError as errc:\n",
        "        print(f\"Error Connecting: {errc}\")\n",
        "    except requests.exceptions.Timeout as errt:\n",
        "        print(f\"Timeout Error: {errt}\")\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        print(f\"Request Exception: {err}\")\n",
        "    except UnidentifiedImageError as ui_err:\n",
        "        print(f\"Unidentified Image Error: {ui_err}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Exception occurred: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "# Example usage: Classify an image from a Google URL\n",
        "google_image_url = \"https://static8.depositphotos.com/1005629/806/i/450/depositphotos_8068134-stock-photo-pasta-with-olives-and-parsley.jpg\"  # Replace with your actual image URL\n",
        "predicted_label = classify_google_image(google_image_url, scripted_model, label_encoder, device)\n",
        "if predicted_label:\n",
        "    print(\"Predicted Label with Scripted Model:\", predicted_label)\n",
        "else:\n",
        "    print(\"Failed to classify image.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9RPC-TEkTHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}